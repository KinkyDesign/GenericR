datpred <-list(predictions=lh_preds)
return(datpred)
}
predictgeneric(jsonReq$dataset, jsonReq$rawModel, jsonReq$additionalInfo)
dataset$dataEntry[,2]
jsonReq$dataset$dataEntry[,2]
jsonReq$dataset$dataEntry[,1]
jsonReq$dataset$dataEntry[,3]
jsonReq$dataset$dataEntry[1,2]
jsonReq$dataset$dataEntry
jsonReq$dataset$dataEntry[,2]
jsonReq$dataset$dataEntry[0,2]
jsonReq$dataset$dataEntry[0,3]
dim(jsonReq$dataset$dataEntry)
typeof(jsonReq$dataset$dataEntry)
length(jsonReq$dataset$dataEntry)
jsonReq$dataset$dataEntry[1]
jsonReq$dataset$dataEntry[1]
jsonReq$dataset$dataEntry[,1]
jsonReq$dataset$dataEntry[2]
jsonReq$dataset$dataEntry[3]
jsonReq$dataset$dataEntry[1]
jsonReq$dataset$dataEntry[1,1]
jsonReq$dataset$dataEntry[1][1]
dataset$dataEntry$values[1]
jsonReq$dataset$dataEntry$values[1]
jsonReq$dataset$dataEntry$values[]
jsonReq$dataset$dataEntry$values
jsonReq$dataset$dataEntry$values[,1]
jsonReq$dataset$dataEntry
jsonReq$dataset$dataEntry[1][1]
jsonReq$dataset$dataEntry[1][[1]]
jsonReq$dataset$dataEntry[1][[1]][1]
jsonReq$dataset$dataEntry[1][[1]][2]
jsonReq$dataset$dataEntry[1][[1]][2][1]
jsonReq$dataset$dataEntry[1][[1]][2][1][1]
jsonReq$dataset$dataEntry[1][[1]][2][1]
jsonReq$dataset$dataEntry[1][[1]][2]
colnames(jsonReq$dataset$dataEntry[1][[1]][2])
colnames(jsonReq$dataset$dataEntry[1][[1]])
colnames(jsonReq$dataset$dataEntry[1])
colnames(jsonReq$dataset$dataEntry[,1])
colnames(jsonReq$dataset$dataEntry[1])
jsonReq$dataset$dataEntry
jsonReq$dataset$dataEntry
jsonReq$dataset$dataEntry[1]
jsonReq <- rjson::fromJSON(file = '/Users/pantelispanka/Desktop/predReq.json')
jsonReq$dataset$dataEntry[1]
jsonReq$dataset$dataEntry[2]
jsonReq$dataset$dataEntry
jsonReq$dataset$dataEntry[]
jsonReq$dataset$dataEntry[][1]
jsonReq$dataset$dataEntry[,1]
jsonReq$dataset$dataEntry[,[1]]
jsonReq$dataset$dataEntry[[,1]]
jsonReq$dataset$dataEntry[[1]]
jsonReq$dataset$dataEntry[[2]]
jsonReq$dataset$dataEntry[[1]]
dataset$dataEntry$values
jsonReq$dataset$dataEntry$values
j <- jsonlite::fromJSON(jsonReq)
j <- jsonlite::fromJSON(/Users/pantelispanka/Desktop/predReq1.txt'')
j <- jsonlite::fromJSON('/Users/pantelispanka/Desktop/predReq1.txt')
j$dataset$dataEntry$values
colnames(j$dataset$dataEntry$values)
predictgeneric <- function(dataset, rawModel, additionalInfo){
feats <- colnames(dataset$dataEntry)
rows_data <- length(dataset$dataEntry$values[,2])
df <- data.frame(matrix(0, ncol = 0, nrow = rows_data))
for(i in feats){
fe <- additionalInfo$independentFeatures[i][[i]]
feval <- dataset$dataEntry$values[i][,1]
df[fe] <- feval
}
mod <- unserialize(base64_dec(rawModel))
model <- mod$MODEL
predFeat <- additionalInfo$predictedFeatures[1][[1]]
predictions <- predict(model, df)
for(i in 1:length(predictions)){
prediction<- data.frame(predictions[i])
colnames(prediction)<- predFeat
if(i==1){lh_preds<- list(unbox(prediction))
}else{
lh_preds[[i]]<- unbox(prediction)
}
}
datpred <-list(predictions=lh_preds)
return(datpred)
}
predictgeneric(j$dataset, j$rawModel, j$additionalInfo)
feats <- colnames(dataset$dataEntry)
dataset <- j$dataset
rawModel <- j$rawModel
additionalInfo <- j$additionalInfo
feats <- colnames(dataset$dataEntry)
rows_data <- length(dataset$dataEntry$values[,2])
df <- data.frame(matrix(0, ncol = 0, nrow = rows_data))
for(i in feats){
fe <- additionalInfo$independentFeatures[i][[i]]
feval <- dataset$dataEntry$values[i][,1]
df[fe] <- feval
}
dataset$dataEntry$values[1][,1]
dataset$dataEntry$values[2][,1]
fe
additionalInfo$independentFeatures[1][[1]]
additionalInfo$independentFeatures[1][[2]]
additionalInfo$independentFeatures[1][[1]]
additionalInfo$independentFeatures[2][[2]]
additionalInfo$independentFeatures[2][[1]]
additionalInfo$independentFeatures[3][[1]]
for(i in feats){
fe <- additionalInfo$independentFeatures[i][[1]]
feval <- dataset$dataEntry$values[i][,1]
df[fe] <- feval
}
for(i in feats){
print(i)
fe <- additionalInfo$independentFeatures[i][[1]]
feval <- dataset$dataEntry$values[i][,1]
df[fe] <- feval
}
additionalInfo$independentFeatures
additionalInfo$independentFeatures[1]
additionalInfo$independentFeatures[,1]
additionalInfo$independentFeatures[]
feats
colnames(dataset$dataEntry)
colnames(dataset$dataEntry$values)
feats <- colnames(dataset$dataEntry$values)
rows_data <- length(dataset$dataEntry$values[,2])
df <- data.frame(matrix(0, ncol = 0, nrow = rows_data))
for(i in feats){
print(i)
fe <- additionalInfo$independentFeatures[i][[1]]
feval <- dataset$dataEntry$values[i][,1]
df[fe] <- feval
}
for(i in feats){
fe <- additionalInfo$independentFeatures[i][[1]]
feval <- dataset$dataEntry$values[i][,1]
df[fe] <- feval
}
mod <- unserialize(base64_dec(rawModel))
model <- mod$MODEL
predFeat <- additionalInfo$predictedFeatures[1][[1]]
df
predictions <- predict(model, df)
for(i in 1:length(predictions)){
prediction<- data.frame(predictions[i])
colnames(prediction)<- predFeat
if(i==1){lh_preds<- list(unbox(prediction))
}else{
lh_preds[[i]]<- unbox(prediction)
}
}
datpred <-list(predictions=lh_preds)
jsonlite::toJSON(datpred)
library(GenericR)
require(roxygen2)
library(GenericR)
predictgeneric <- function(dataset, rawModel, additionalInfo){
feats <- colnames(dataset$dataEntry$values)
rows_data <- length(dataset$dataEntry$values[,2])
df <- data.frame(matrix(0, ncol = 0, nrow = rows_data))
for(i in feats){
fe <- additionalInfo$independentFeatures[i][[1]]
feval <- dataset$dataEntry$values[i][,1]
df[fe] <- feval
}
mod <- unserialize(base64_dec(rawModel))
model <- mod$MODEL
predFeat <- additionalInfo$predictedFeatures[1][[1]]
predictions <- predict(model, df)
for(i in 1:length(predictions)){
prediction<- data.frame(predictions[i])
colnames(prediction)<- predFeat
if(i==1){lh_preds<- list(unbox(prediction))
}else{
lh_preds[[i]]<- unbox(prediction)
}
}
datpred <-list(predictions=lh_preds)
return(datpred)
}
predictgeneric(j$dataset, j$rawModel, j$additionalInfo)
library(GenericR)
library(roxygen2)
install.packages("roxygen2")
library(roxygen2)
library(GenericR)
library(GenericR)
library(GenericR)
library(GenericR)
library(GenericR)
library(jsonlite)
json <- fromJSON('/Users/pantelispanka/Desktop/pred.json')
json
predict.rpart(json$dataset, json$rawModel, json$additionalInfo)
json$rawModel
unserialize(rawModel)
jsonlite::base64_dec(json$rawModel)
t <- jsonlite::base64_dec(json$rawModel)
mod <- unserialize(t)
mod$MODEL
json <- fromJSON('/Users/pantelispanka/Desktop/pred.json')
json
predict.rpart(json$dataset, json$rawModel, json$additionalInfo)
dataset <- json$dataset
rawModel <- json$rawModel
additionalInfo <- json$additionalInfo
feat.keys <-  dataset$features$key
# Get feature names (actual name)
feat.names <- dataset$features$name
# Create a dataframe that includes the feature key and the corresponding name
key.match <- data.frame(cbind(feat.keys, feat.names))
# Convert factor to string (feat.names is converted factor by data.frame())
key.match[] <- lapply(key.match, as.character)
# Initialize a dataframe with as many rows as the number of values per feature
rows_data <- length(dataset$dataEntry$values[,2])
df <- data.frame(matrix(0, ncol = 0, nrow = rows_data))
for(key in feat.keys){
# For each key (feature) get the vector of values (of length 'row_data')
feval <- dataset$dataEntry$values[key][,1]
# Name the column with the corresponding name that is connected with the key
df[key.match[key.match$feat.keys == key, 2]] <- feval
}
# Unserialize the model
decoded <- jsonlite::base64_dec(rawModel)
mod <- unserialize(decoded)
model <- mod$MODEL
# Extract the predicted value names
predFeat <- additionalInfo$predictedFeatures[1][[1]]
# Make the prediction using the model and the new data
# Note that the names of the dataframe must be the same with the original
predictions <- predict(model, df)
for(i in 1:length(predictions)){
prediction<- data.frame(predictions[i])
colnames(prediction)<- predFeat
if(i==1){lh_preds<- list(jsonlite::unbox(prediction))
}else{
lh_preds[[i]]<- jsonlite::unbox(prediction)
}
}
datpred <-list(predictions=lh_preds)
return(datpred)
feat.keys <-  dataset$features$key
# Get feature names (actual name)
feat.names <- dataset$features$name
# Create a dataframe that includes the feature key and the corresponding name
key.match <- data.frame(cbind(feat.keys, feat.names))
# Convert factor to string (feat.names is converted factor by data.frame())
key.match[] <- lapply(key.match, as.character)
# Initialize a dataframe with as many rows as the number of values per feature
rows_data <- length(dataset$dataEntry$values[,2])
df <- data.frame(matrix(0, ncol = 0, nrow = rows_data))
for(key in feat.keys){
# For each key (feature) get the vector of values (of length 'row_data')
feval <- dataset$dataEntry$values[key][,1]
# Name the column with the corresponding name that is connected with the key
df[key.match[key.match$feat.keys == key, 2]] <- feval
}
decoded <- jsonlite::base64_dec(rawModel)
mod <- unserialize(decoded)
model <- mod$MODEL
predFeat <- additionalInfo$predictedFeatures[1][[1]]
predictions <- predict(model, df)
require(rpart)
predict(model, df)
predictions <- predict(model, df)
predictions
for(i in 1:length(predictions)){
prediction<- data.frame(predictions[i])
colnames(prediction)<- predFeat
if(i==1){lh_preds<- list(jsonlite::unbox(prediction))
}else{
lh_preds[[i]]<- jsonlite::unbox(prediction)
}
}
datpred <-list(predictions=lh_preds)
datpred
detach(rpart())
detach(rpart
)
detach('package:rpart')
predictions <- predict(model, df)
predictions
feat.keys <-  dataset$features$key
# Get feature names (actual name)
feat.names <- dataset$features$name
# Create a dataframe that includes the feature key and the corresponding name
key.match <- data.frame(cbind(feat.keys, feat.names))
# Convert factor to string (feat.names is converted factor by data.frame())
key.match[] <- lapply(key.match, as.character)
# Initialize a dataframe with as many rows as the number of values per feature
rows_data <- length(dataset$dataEntry$values[,2])
df <- data.frame(matrix(0, ncol = 0, nrow = rows_data))
for(key in feat.keys){
# For each key (feature) get the vector of values (of length 'row_data')
feval <- dataset$dataEntry$values[key][,1]
# Name the column with the corresponding name that is connected with the key
df[key.match[key.match$feat.keys == key, 2]] <- feval
}
# Unserialize the model
decoded <- jsonlite::base64_dec(rawModel)
mod <- unserialize(decoded)
model <- mod$MODEL
# Extract the predicted value names
predFeat <- additionalInfo$predictedFeatures[1][[1]]
# Make the prediction using the model and the new data
# Note that the names of the dataframe must be the same with the original
predictions <- predict(model, df)
for(i in 1:length(predictions)){
prediction<- data.frame(predictions[i])
colnames(prediction)<- predFeat
if(i==1){lh_preds<- list(jsonlite::unbox(prediction))
}else{
lh_preds[[i]]<- jsonlite::unbox(prediction)
}
}
datpred <-list(predictions=lh_preds)
datpred
library(GenericR)
library(GenericR)
predict.rpart.jaqpot(json$dataset, json$rawModel, json$additionalInfo)
predict.rpart.jaqpot(json$dataset, json$rawModel, json$additionalInfo)
install.packages(party)
install.packages('party')
require(party)
View(dataset)
pertymodel <- ctree(Survived ~ Age + Parch + Fare, data = data)
Titanic
pertymodel <- ctree(Survived ~ Age + Parch + Fare, data = Titanic)
ml <- array(ml)
jsonr <- jsonlite::fromJSON("/Users/pantelispanka/Desktop/pred.json")
predict.pbpk <- function(dataset, rawModel, additionalInfo){
###########################################
### Create input vector from Jaqpot format
##########################################
# Get the number of compartments of the PBPK model
n_comp <- length(additionalInfo$predictedFeatures) - 1
# Get feature keys (a key number that points to the url)
feat.keys <-  dataset$features$key
# Get feature names (actual name)
feat.names <- dataset$features$name
# Create a dataframe that includes the feature key and the corresponding name
key.match <- data.frame(cbind(feat.keys, feat.names))
# Convert factor to string (feat.names is converted factor by data.frame())
key.match[] <- lapply(key.match, as.character)
# Initialize a dataframe with as many rows as the number of values per feature
rows_data <- length(dataset$dataEntry$values[,2])
df <- data.frame(matrix(0, ncol = 0, nrow = rows_data))
for(key in feat.keys){
# For each key (feature) get the vector of values (of length 'row_data')
feval <- dataset$dataEntry$values[key][,1]
# Name the column with the corresponding name that is connected with the key
df[key.match[key.match$feat.keys == key, 2]] <- feval
}
####################################
### Continue with prediction process
####################################
# Unserialize the ODEs and the covariate model
mod <- unserialize(jsonlite::base64_dec(rawModel))
# Extract function for parameter creation
create.params <- mod$create.params
# Extract function for initial conditions of odes creation
create.inits <- mod$create.inits
# Extract function for event creation
create.events <- mod$create.events
# Extract custom function
custom.func <- mod$custom.func
# Extract odes function
ode.func <- mod$ode.func
# Create parameter vector
params <- create.params(df)
# Create initial conditions
inits <- create.inits(params)
# Create events
events <- create.events(params)
# Get the names of compartments in the same order as represented by the ODEs
###comp  <- additionalInfo$fromUser$comp
# Generate a time vector based on the user input
sample_time <- seq(df$sim.start , df$sim.end, df$sim.step)
if (!(df$solver %in%  c( "lsoda", "lsode", "lsodes", "lsodar", "vode","daspk", "bdf",
"adams", "impAdams", "radau") ) ){
solver <- "lsodes"
## TODO : create correpsonding error message
}else{
solver <- df$solver
}
# Integrate the ODEs using the deSolve package
solution <- deSolve::ode(times = sample_time,  func = ode.func, y = inits, parms = params,
custom.func = custom.func, method = solver,  events = events)
for(i in 1:dim(solution)[1]){
prediction<- data.frame(t(solution[i,]))
# Name the predictions
###  colnames(prediction)<- c("time", comp)
# Bring everything into a format that cooperates with Jaqpot
if(i==1){lh_preds<- list(jsonlite::unbox(prediction))
}else{
lh_preds[[i]]<- jsonlite::unbox(prediction)
}
}
datpred <-list(predictions=lh_preds)
return(datpred)
}
require(deSolve)
jsonr <- jsonlite::fromJSON("/Users/pantelispanka/Desktop/pred.json")
predict.pbpk(json$dataset, jsonr$rawModel, jsonr$additionalInfo)
predict.pbpk <- function(dataset, rawModel, additionalInfo){
###########################################
### Create input vector from Jaqpot format
##########################################
# Get the number of compartments of the PBPK model
n_comp <- length(additionalInfo$predictedFeatures) - 1
# Get feature keys (a key number that points to the url)
feat.keys <-  dataset$features$key
# Get feature names (actual name)
feat.names <- dataset$features$name
# Create a dataframe that includes the feature key and the corresponding name
key.match <- data.frame(cbind(feat.keys, feat.names))
# Convert factor to string (feat.names is converted factor by data.frame())
key.match[] <- lapply(key.match, as.character)
# Initialize a dataframe with as many rows as the number of values per feature
rows_data <- length(dataset$dataEntry$values[,2])
data.feats <- list()
for(key in feat.keys){
# For each key (feature) get the vector of values (of length 'row_data')
feval <- dataset$dataEntry$values[key][,1]
# Name the column with the corresponding name that is connected with the key
data.feats[key.match[key.match$feat.keys == key, 2]] <- feval
}
# Check if the model includes any ellipses arguments (...), which the model creator
# uses to define parameters of the solver
ode.method <- additionalInfo$fromUser$method
if (!(ode.method %in% c("lsoda", "lsode", "lsodes", "lsodar", "vode", "daspk","euler", "rk4", "ode23",
"ode45", "radau","bdf", "bdf_d", "adams", "impAdams", "impAdams_d", "iteration"))){
ode.method <- "lsodes"
}
extra.args <- additionalInfo$fromUser$extra.args
####################################
### Continue with prediction process
####################################
# Unserialize the ODEs and the covariate model
mod <- unserialize(jsonlite::base64_dec(rawModel))
# Extract function for parameter creation
create.params <- mod$create.params
# Extract function for initial conditions of odes creation
create.inits <- mod$create.inits
# Extract function for event creation
create.events <- mod$create.events
# Extract custom function
custom.func <- mod$custom.func
# Extract odes function
ode.func <- mod$ode.func
# Create parameter vector
params <- create.params(data.feats)
# Create initial conditions
inits <- create.inits(params)
# Create events
events <- create.events(params)
# Get the names of compartments in the same order as represented by the ODEs
###comp  <- additionalInfo$fromUser$comp
# Generate a time vector based on the user input
sample_time <- seq(data.feats$sim.start , data.feats$sim.end, data.feats$sim.step)
# Integrate the ODEs using the deSolve package
solution <- do.call(deSolve::ode, c(list(times = sample_time,  func = ode.func, y = inits, parms = params,
custom.func = custom.func, method = ode.method,  events = events), extra.args))
for(i in 1:dim(solution)[1]){
prediction<- data.frame(t(solution[i,]))
# Name the predictions
###  colnames(prediction)<- c("time", comp)
# Bring everything into a format that cooperates with Jaqpot
if(i==1){lh_preds<- list(jsonlite::unbox(prediction))
}else{
lh_preds[[i]]<- jsonlite::unbox(prediction)
}
}
datpred <-list(predictions=lh_preds)
return(datpred)
}
jsonr <- jsonlite::fromJSON('/Users/pantelispanka/Desktop/pred.json')
predict.pbpk(jsonr$dataset, jsonr$rawModel, jsonr$additionalInfo)
preds <-
predict.pbpk(jsonr$dataset, jsonr$rawModel, jsonr$additionalInfo)
preds
preds[0]
preds[[1]]
View(preds)
jsonlite::toJSON(preds)
prediction
datpred
data <- read.csv('/Users/pantelispanka/Desktop/gdp-countries.csv')
data
lmod <- lm(GDP ~ LFG + EQP + NEQ + GAP, data =data)
plot(lmod)
plot(lmod)
summary(lmod)
lmod <- lm(GDP ~ LFG + EQP + NEQ + GAP + EQP^2, data =data)
summary(lmod)
summary(lmod)
plot(lmod)
lmod <- lm(GDP ~ LFG + EQP + NEQ + GAP + GSP^2, data =data)
lmod <- lm(GDP ~ LFG + EQP + NEQ + GAP + GAP^2, data =data)
plot(lmod)
summary(lmod)
ols_mallows_cp(lmod)
lmod <- lm(GDP ~ EQP + GAP, data =data)
summary(lmod)
lmod <- lm(GDP ~ EQP, data =data)
summary(lmod)
plot(lmod)
